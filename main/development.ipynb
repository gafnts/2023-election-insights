{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development\n",
    "\n",
    "Agreement and policy: https://developer.twitter.com/en/developer-terms/agreement-and-policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from modules import (\n",
    "    TwitterRequest,\n",
    "    GPTFeatureExtractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2023, 4, 27, 00, 00)\n",
    "end_date = datetime(2023, 4, 29, 00, 00)\n",
    "    \n",
    "candidates = [\n",
    "    'carlos pineda', 'sandra torres'\n",
    "]\n",
    "\n",
    "max_results = 10\n",
    "tweets_prefix = 'tw_'\n",
    "users_prefix = 'us_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterGPTDataProcessor:\n",
    "    def __init__(\n",
    "            self, \n",
    "            candidates: list[str], \n",
    "            start_date: datetime,\n",
    "            end_date: datetime, \n",
    "            max_results: int,\n",
    "            tweets_prefix: str, \n",
    "            users_prefix: str\n",
    "        ) -> None:\n",
    "        self.candidates = candidates\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.max_results = max_results\n",
    "        self.tweets_prefix = tweets_prefix\n",
    "        self.users_prefix = users_prefix\n",
    "\n",
    "    def generate_dates(self) -> \"TwitterGPTDataProcessor\":\n",
    "        delta = timedelta(days=1)\n",
    "        self.dates = []\n",
    "\n",
    "        while self.start_date < self.end_date:\n",
    "            self.next_date = self.start_date + delta\n",
    "            self.dates.append(\n",
    "                (self.start_date.isoformat() + \"Z\", self.next_date.isoformat() + \"Z\")\n",
    "            )\n",
    "            self.start_date = self.next_date\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fetch_twitter_data(self, candidate: str, start_date: datetime, end_date: datetime) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        tweets, users = (\n",
    "            TwitterRequest(\n",
    "                query=candidate,\n",
    "                start_time=start_date,\n",
    "                end_time=end_date,\n",
    "                max_results=self.max_results\n",
    "            )\n",
    "            .request()\n",
    "            .extract_tweets()\n",
    "            .extract_users()\n",
    "            .segregate()\n",
    "            .preprocess(\n",
    "                tweets_prefix=self.tweets_prefix,\n",
    "                users_prefix=self.users_prefix\n",
    "            )\n",
    "        )\n",
    "        return tweets, users\n",
    "\n",
    "    def process_data_with_gpt(self, tweets: pd.DataFrame, users: pd.DataFrame, candidate: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        tweets_with_gpt_features = (\n",
    "            GPTFeatureExtractor(tweets=tweets)\n",
    "            .preprocess_text()\n",
    "            .extract_features(prefix=self.tweets_prefix)\n",
    "        )\n",
    "\n",
    "        tweets_with_gpt_features[f\"{self.tweets_prefix}candidate\"] = candidate\n",
    "        users[f\"{self.users_prefix}candidate\"] = candidate\n",
    "\n",
    "        return tweets_with_gpt_features, users\n",
    "\n",
    "    def collect_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        self.generate_dates()\n",
    "        tweets_collector, users_collector = [], []\n",
    "        \n",
    "        for candidate in self.candidates:\n",
    "            dates_tweets_collector, dates_users_collector = [], []\n",
    "            \n",
    "            for start_date, end_date in self.dates:\n",
    "                tweets, users = self.fetch_twitter_data(candidate, start_date, end_date)\n",
    "                tweets_with_gpt_features, users = self.process_data_with_gpt(tweets, users, candidate)\n",
    "\n",
    "                dates_tweets_collector.append(tweets_with_gpt_features)\n",
    "                dates_users_collector.append(users)\n",
    "\n",
    "            tweets_collector.append(pd.concat(dates_tweets_collector))\n",
    "            users_collector.append(pd.concat(dates_users_collector))\n",
    "\n",
    "        self.tweets = pd.concat(tweets_collector, axis=0, ignore_index=True)\n",
    "        self.users = pd.concat(users_collector, axis=0, ignore_index=True)\n",
    "\n",
    "        return self.tweets, self.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TwitterGPTDataProcessor(\n",
    "    candidates=candidates,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    max_results=max_results,\n",
    "    tweets_prefix=tweets_prefix,\n",
    "    users_prefix=users_prefix\n",
    ")\n",
    "\n",
    "tweets, users = processor.collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('tweets_processed.csv', index=False)\n",
    "users.to_csv('users_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
