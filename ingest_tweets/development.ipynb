{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development\n",
    "\n",
    "Agreement and policy: https://developer.twitter.com/en/developer-terms/agreement-and-policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import tweepy\n",
    "import requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from authenticators import (\n",
    "    TwitterAuthenticator, RDSAuthenticator\n",
    ")\n",
    "\n",
    "twitter = TwitterAuthenticator()\n",
    "client = tweepy.Client(bearer_token=twitter.bearer_token)\n",
    "\n",
    "rds = RDSAuthenticator()\n",
    "connection = psycopg2.connect(\n",
    "    host = rds.host,\n",
    "    port = rds.port,\n",
    "    database= rds.database,\n",
    "    user = rds.user,\n",
    "    password = rds.password\n",
    ")\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿En qué necesito pensar?\n",
    "\n",
    "- Conectarme a RDS\n",
    "- Esquema para extraer datos uniformemente durante los últimos 7 días\n",
    "- Establecer qué políticos tomar en cuenta. Scrape the list from here: https://es.wikipedia.org/wiki/Elecciones_generales_de_Guatemala_de_2023\n",
    "- ¿Guardar los datos en una base de datos SQL local?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query: str, start_time: str, end_time: str, max_results: int) -> requests.Response:\n",
    "    query = query = f\"{query} -is:retweet -is:reply\"\n",
    "    tweets = client.search_recent_tweets(\n",
    "        query = query,\n",
    "        start_time = start_time,\n",
    "        end_time = end_time,\n",
    "        max_results = max_results,\n",
    "        tweet_fields = [\n",
    "            \"id\", \"author_id\", \"created_at\", \"text\", \n",
    "            \"public_metrics\", \"possibly_sensitive\", \"lang\"\n",
    "        ],\n",
    "        user_fields = [\n",
    "            \"id\", \"username\", \"name\", \"location\", \"created_at\", \"description\", \n",
    "            \"profile_image_url\", \"verified\", \"public_metrics\"\n",
    "        ],\n",
    "        expansions = [\n",
    "            \"author_id\", \"referenced_tweets.id\"\n",
    "        ]\n",
    "    )\n",
    "    return tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process them into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataCleaner:\n",
    "    def __init__(self, tweets: requests.Response):\n",
    "        self.tweets = tweets\n",
    "        self.df = None\n",
    "\n",
    "    def clean(self) -> pd.DataFrame:\n",
    "        self.extract_tweet_data()\n",
    "        self.extract_user_data()\n",
    "\n",
    "        tweets_df, users_df = self.segregate_data()\n",
    "        return tweets_df, users_df\n",
    "\n",
    "    def extract_tweet_data(self):\n",
    "        tweet_data = []\n",
    "        for tweet in self.tweets.data:\n",
    "            tweet_dict = {key: getattr(tweet, key) for key in tweet.data.keys()}\n",
    "            public_metrics = tweet_dict.pop('public_metrics')\n",
    "            tweet_dict.update(public_metrics)\n",
    "            tweet_data.append(tweet_dict)\n",
    "\n",
    "        self.df = pd.DataFrame(tweet_data)\n",
    "\n",
    "    def extract_user_data(self):\n",
    "        users = {user.id: user for user in self.tweets.includes['users']}\n",
    "        for key, user in users.items():\n",
    "            user_data = {f\"user_{key}\": getattr(user, key) for key in user.data.keys()}\n",
    "            public_metrics_user = user_data.pop('user_public_metrics')\n",
    "            user_data.update({f\"user_{k}\": v for k, v in public_metrics_user.items()})\n",
    "            users[key] = user_data\n",
    "\n",
    "        self.df['user_data'] = self.df['author_id'].apply(lambda x: users[x])\n",
    "\n",
    "        user_columns = pd.json_normalize(self.df['user_data']).columns\n",
    "        for col in user_columns:\n",
    "            self.df[col] = self.df['user_data'].apply(lambda x: x.get(col, None))\n",
    "\n",
    "        self.df = self.df.drop(columns = ['user_data'])\n",
    "\n",
    "    def segregate_data(self):\n",
    "        tweets_df = self.df[[\n",
    "            \"id\", \"author_id\", \"created_at\", \"text\", \"possibly_sensitive\", \"retweet_count\",\n",
    "            \"reply_count\", \"like_count\", \"quote_count\", \"impression_count\", \"lang\"\n",
    "        ]]\n",
    "\n",
    "        users_df = self.df[[\n",
    "            \"user_id\", \"user_username\", \"user_name\", \"user_location\", \"user_created_at\",\n",
    "            \"user_description\", \"user_profile_image_url\", \"user_verified\",\n",
    "            \"user_followers_count\", \"user_following_count\", \"user_tweet_count\", \"user_listed_count\"\n",
    "        ]]\n",
    "\n",
    "        return tweets_df, users_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store them in a RDS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'column1': [1, 2, 3],\n",
    "    'column2': ['A', 'B', 'C']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Upload the DataFrame to your PostgreSQL instance\n",
    "# Replace \"your_table_name\" with the desired table name\n",
    "df.to_sql('your_table_name', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through multiple days and candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Debería hacer append a un dataframe o cargar los datos a una base de datos SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates = [\n",
    "#     'JoeBiden', 'KamalaHarris', 'BernieSanders'\n",
    "# ]\n",
    "\n",
    "# for candidate in candidates:\n",
    "#     query = candidate\n",
    "\n",
    "#     for date in dates:\n",
    "#         start_time = '2021-01-01T00:00:00Z'\n",
    "#         end_time = '2021-01-02T00:00:00Z'\n",
    "#         max_results = 10\n",
    "\n",
    "#         tweets_call = get_tweets(query, start_time, end_time, max_results)\n",
    "#         cleaner = TwitterDataCleaner(tweets_call)\n",
    "#         tweets, users = cleaner.clean()\n",
    "        \n",
    "#         ingest_tweets(tweets, users, path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'jimmy morales'\n",
    "start_time = \"2023-04-25T00:00:00Z\" \n",
    "end_time = \"2023-04-28T00:00:00Z\" \n",
    "max_results = 10\n",
    "\n",
    "tweets_call = get_tweets(\n",
    "    query=query,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_results=max_results,\n",
    ")\n",
    "\n",
    "data_cleaner = TwitterDataCleaner(tweets_call)\n",
    "tweets, users = data_cleaner.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
